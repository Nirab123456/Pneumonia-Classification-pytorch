{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transforms using torchvision.transforms as transforms\n",
    "# library\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in each dataset and apply transformations using\n",
    "# the torchvision.datasets as datasets library\n",
    "train_set = datasets.ImageFolder(\"D:/learn_django_v3/x-ray/chest_xray/train/\", transform = transformations)\n",
    "val_set = datasets.ImageFolder(\"D:/learn_django_v3/x-ray/chest_xray/val/\", transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify transforms using torchvision.transforms as transforms\n",
    "# library\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Load in each dataset and apply transformations using\n",
    "# the torchvision.datasets as datasets library\n",
    "train_set = datasets.ImageFolder(\"D:/learn_django_v3/x-ray/chest_xray/train/\", transform = transformations)\n",
    "val_set = datasets.ImageFolder(\"D:/learn_django_v3/x-ray/chest_xray/val/\", transform = transformations)\n",
    "# Put into a Dataloader using torch library\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size =128, shuffle=True)\n",
    "# Get pretrained model using torchvision.models as models library\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Turn off training for their parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model using torchvision.models as models library\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Turn off training for their parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,353,574 total parameters.\n",
      "177,062 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Create new classifier for model using torch.nn as nn library\n",
    "classifier_input = model.fc.in_features\n",
    "num_labels = 2\n",
    "classifier = nn.Sequential(nn.Linear(classifier_input, 100),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(100, 512),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(p=0.5),\n",
    "                            nn.Linear(512, 128),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(p=0.5),\n",
    "                            nn.Linear(128, 64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(p=0.5),\n",
    "                            nn.Linear(64, num_labels),\n",
    "                            nn.LogSoftmax(dim=1))\n",
    "model.fc = classifier\n",
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.5674, acc 0.7368\n",
      "Model saved as model_epoch_0.pt\n",
      "val loss: 0.8387, acc 0.5000\n",
      "--------------------\n",
      "training loss: 0.3170, acc 0.8037\n",
      "Model saved as model_epoch_1.pt\n",
      "val loss: 0.4698, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.1899, acc 0.9394\n",
      "Model saved as model_epoch_2.pt\n",
      "val loss: 0.8454, acc 0.6250\n",
      "--------------------\n",
      "training loss: 0.1453, acc 0.9486\n",
      "Model saved as model_epoch_3.pt\n",
      "val loss: 0.4468, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.1242, acc 0.9574\n",
      "Model saved as model_epoch_4.pt\n",
      "val loss: 0.7371, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.1291, acc 0.9565\n",
      "Model saved as model_epoch_5.pt\n",
      "val loss: 0.5150, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.1075, acc 0.9613\n",
      "Model saved as model_epoch_6.pt\n",
      "val loss: 0.6101, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0973, acc 0.9670\n",
      "Model saved as model_epoch_7.pt\n",
      "val loss: 0.5851, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0944, acc 0.9664\n",
      "Model saved as model_epoch_8.pt\n",
      "val loss: 0.6733, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0940, acc 0.9688\n",
      "Model saved as model_epoch_9.pt\n",
      "val loss: 0.7940, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.0970, acc 0.9649\n",
      "Model saved as model_epoch_10.pt\n",
      "val loss: 0.5236, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0932, acc 0.9666\n",
      "Model saved as model_epoch_11.pt\n",
      "val loss: 0.5137, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0847, acc 0.9693\n",
      "Model saved as model_epoch_12.pt\n",
      "val loss: 0.9295, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.0818, acc 0.9716\n",
      "Model saved as model_epoch_13.pt\n",
      "val loss: 0.5725, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0690, acc 0.9755\n",
      "Model saved as model_epoch_14.pt\n",
      "val loss: 0.4818, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0769, acc 0.9747\n",
      "Model saved as model_epoch_15.pt\n",
      "val loss: 0.8866, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.0710, acc 0.9753\n",
      "Model saved as model_epoch_16.pt\n",
      "val loss: 1.0757, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.0735, acc 0.9749\n",
      "Model saved as model_epoch_17.pt\n",
      "val loss: 0.5993, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0793, acc 0.9716\n",
      "Model saved as model_epoch_18.pt\n",
      "val loss: 0.3416, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0706, acc 0.9783\n",
      "Model saved as model_epoch_19.pt\n",
      "val loss: 0.8987, acc 0.6875\n",
      "--------------------\n",
      "training loss: 0.0755, acc 0.9749\n",
      "Model saved as model_epoch_20.pt\n",
      "val loss: 0.6735, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0642, acc 0.9774\n",
      "Model saved as model_epoch_21.pt\n",
      "val loss: 1.3243, acc 0.6250\n",
      "--------------------\n",
      "training loss: 0.0626, acc 0.9783\n",
      "Model saved as model_epoch_22.pt\n",
      "val loss: 0.3648, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0627, acc 0.9783\n",
      "Model saved as model_epoch_23.pt\n",
      "val loss: 0.7860, acc 0.7500\n",
      "--------------------\n",
      "training loss: 0.0551, acc 0.9806\n",
      "Model saved as model_epoch_24.pt\n",
      "val loss: 0.4904, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0580, acc 0.9797\n",
      "Model saved as model_epoch_25.pt\n",
      "val loss: 0.5104, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0502, acc 0.9824\n",
      "Model saved as model_epoch_26.pt\n",
      "val loss: 1.2579, acc 0.6250\n",
      "--------------------\n",
      "training loss: 0.0494, acc 0.9824\n",
      "Model saved as model_epoch_27.pt\n",
      "val loss: 0.3499, acc 0.8750\n",
      "--------------------\n",
      "training loss: 0.0489, acc 0.9835\n",
      "Model saved as model_epoch_28.pt\n",
      "val loss: 0.6028, acc 0.8125\n",
      "--------------------\n",
      "training loss: 0.0502, acc 0.9826\n",
      "Model saved as model_epoch_29.pt\n",
      "val loss: 1.1178, acc 0.6250\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Optimizer and Loss Function\n",
    "writer = SummaryWriter()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00021367223615921426)\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(train_set)\n",
    "    epoch_acc = running_corrects.double() / len(train_set)\n",
    "    writer.add_scalar('training loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('training acc', epoch_acc, epoch)\n",
    "    print(f'training loss: {epoch_loss:.4f}, acc {epoch_acc:.4f}')\n",
    "    model_filename = f'model_epoch_{epoch}.pt'\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f'Model saved as {model_filename}')\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        writer.add_scalar('validation loss', loss.item(), epoch)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(val_set)\n",
    "    epoch_acc = running_corrects.double() / len(val_set)\n",
    "    writer.add_scalar('val loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('val acc', epoch_acc, epoch)\n",
    "    print(f'val loss: {epoch_loss:.4f}, acc {epoch_acc:.4f}')\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Train and validate\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "    print('-' * 20)\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "writer = SummaryWriter()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Train the model\n",
    "epochs = 10\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('training loss',\n",
    "                        running_loss / print_every,\n",
    "                        steps)\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            writer.add_scalar('validation loss',\n",
    "                            test_loss / len(val_loader),\n",
    "                            steps)\n",
    "            writer.add_scalar('accuracy',\n",
    "                            accuracy / len(val_loader),\n",
    "                            steps)\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            test_losses.append(test_loss / len(val_loader))\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss / print_every:.3f}.. \"\n",
    "                f\"Test loss: {test_loss / len(val_loader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy / len(val_loader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
